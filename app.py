# ===== File: app.py (æœ€ç»ˆç¨³å®šç‰ˆ v5.5) =====
import streamlit as st
import pandas as pd
from io import BytesIO
import time
import streamlit.components.v1 as components
import gc
from main_analyzer import analyze_5g_offload
from map_generator import create_folium_map
REQUIRED_COLUMNS = ['å°åŒºåç§°', 'ç»åº¦', 'çº¬åº¦', 'æ–¹ä½è§’']
def load_and_validate_data(uploaded_file, file_type):
    if uploaded_file is None: 
        raise ValueError(f"è¯·å…ˆä¸Šä¼ {file_type}æ–‡ä»¶ã€‚")
    try:
        # è¯»å–æ‰€æœ‰åˆ—åï¼Œç”¨äºéªŒè¯
        all_cols = pd.read_excel(uploaded_file, nrows=0).columns
        
        # æ¸…ç†åˆ—åç©ºæ ¼å¹¶åˆ›å»ºæ˜ å°„
        cleaned_cols_map = {col.strip(): col for col in all_cols}
        
        # éªŒè¯å¿…éœ€åˆ—
        missing_cols = [req_col for req_col in REQUIRED_COLUMNS if req_col not in cleaned_cols_map]
        if missing_cols: 
            raise ValueError(f"{file_type}æ–‡ä»¶ç¼ºå°‘ä»¥ä¸‹å¿…éœ€çš„åˆ—: {', '.join(missing_cols)}")
        
        # åŠ è½½æ‰€æœ‰æ•°æ®ï¼Œä½†åªä¿ç•™å¿…éœ€åˆ—
        cols_to_load = [cleaned_cols_map[req_col] for req_col in REQUIRED_COLUMNS]
        df = pd.read_excel(uploaded_file, usecols=cols_to_load)
        
        # é‡å‘½ååˆ—ä¸ºæ ‡å‡†åç§°
        rename_map = {cleaned_cols_map[req_col]: req_col for req_col in REQUIRED_COLUMNS}
        df.rename(columns=rename_map, inplace=True)
        
        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        if df.empty:
            raise ValueError(f"{file_type}æ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®è¡Œï¼")
        
        # å°†æ•°å€¼åˆ—è½¬æ¢ä¸ºæ•°å­—ç±»å‹
        for col in ['ç»åº¦', 'çº¬åº¦', 'æ–¹ä½è§’']:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # è¿‡æ»¤æ‰åŒ…å«æ— æ•ˆæ•°å€¼çš„è¡Œ
        initial_count = len(df)
        df.dropna(subset=['ç»åº¦', 'çº¬åº¦', 'æ–¹ä½è§’'], inplace=True)
        invalid_count = initial_count - len(df)
        
        if invalid_count > 0:
            st.warning(f"{file_type}æ–‡ä»¶ä¸­å‘ç°{invalid_count}è¡ŒåŒ…å«æ— æ•ˆæ•°å€¼æ•°æ®ï¼Œå·²è‡ªåŠ¨è¿‡æ»¤ã€‚")
        
        # éªŒè¯è¿‡æ»¤åçš„æ•°æ®æ˜¯å¦ä¸ºç©º
        if df.empty:
            raise ValueError(f"{file_type}æ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®è¡Œï¼")
        
        # éªŒè¯åœ°ç†åæ ‡çš„åˆç†æ€§ï¼ˆä¸­å›½åœ°åŒºå¤§è‡´èŒƒå›´ï¼‰
        invalid_lon = ((df['ç»åº¦'] < 73) | (df['ç»åº¦'] > 135)).sum()
        invalid_lat = ((df['çº¬åº¦'] < 18) | (df['çº¬åº¦'] > 53)).sum()
        invalid_azimuth = ((df['æ–¹ä½è§’'] < 0) | (df['æ–¹ä½è§’'] > 360)).sum()
        
        total_invalid = invalid_lon + invalid_lat + invalid_azimuth
        if total_invalid > 0:
            # å†æ¬¡è¿‡æ»¤æ‰è¶…å‡ºåˆç†èŒƒå›´çš„æ•°æ®
            df = df[(df['ç»åº¦'] >= 73) & (df['ç»åº¦'] <= 135) & 
                   (df['çº¬åº¦'] >= 18) & (df['çº¬åº¦'] <= 53) & 
                   (df['æ–¹ä½è§’'] >= 0) & (df['æ–¹ä½è§’'] <= 360)]
            st.warning(f"{file_type}æ–‡ä»¶ä¸­å‘ç°{total_invalid}è¡Œæ•°æ®è¶…å‡ºåˆç†èŒƒå›´ï¼Œå·²è‡ªåŠ¨è¿‡æ»¤ã€‚")
        
        # æœ€åæ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
        if df.empty:
            raise ValueError(f"{file_type}æ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®è¡Œï¼")
        
        # éªŒè¯å°åŒºåç§°åˆ—ä¸ä¸ºç©º
        if df['å°åŒºåç§°'].isnull().any():
            raise ValueError(f"{file_type}æ–‡ä»¶ä¸­çš„'å°åŒºåç§°'åˆ—åŒ…å«ç©ºå€¼ï¼")
        

        
        return df
    except ValueError as ve:
        # ç›´æ¥ä¼ é€’å·²æ ¼å¼åŒ–çš„é”™è¯¯ä¿¡æ¯
        raise ve
    except pd.errors.EmptyDataError:
        raise ValueError(f"{file_type}æ–‡ä»¶ä¸ºç©ºæˆ–æ²¡æœ‰æ•°æ®è¡Œï¼")
    except pd.errors.ParserError:
        raise ValueError(f"{file_type}æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼è¯·ç¡®ä¿ä¸Šä¼ çš„æ˜¯æœ‰æ•ˆçš„Excelæ–‡ä»¶ï¼ˆ.xlsxæˆ–.xlsæ ¼å¼ï¼‰ã€‚")
    except Exception as e:
        raise ValueError(f"è¯»å–{file_type}æ–‡ä»¶æ—¶å‡ºé”™: {type(e).__name__}: {str(e)}. è¯·ç¡®ä¿æ–‡ä»¶æ˜¯æœ‰æ•ˆçš„Excelæ ¼å¼ã€‚")
def display_paginated_dataframe(df, title):
    st.subheader(title)
    if df is None or df.empty: st.warning("è¯·å…ˆä¸Šä¼ æ–‡ä»¶ã€‚"); return
    page_size = 10; total_pages = -(-len(df) // page_size) if len(df) > 0 else 1; page_num_key = f"page_{title}"
    if page_num_key not in st.session_state: st.session_state[page_num_key] = 1
    page_num = st.session_state.get(page_num_key, 1); start_idx = (page_num - 1) * page_size; end_idx = start_idx + page_size
    st.dataframe(df.iloc[start_idx:end_idx])
    col1, col2 = st.columns([3, 1]); 
    with col1: st.write("");
    with col2:
        pagination_container = st.container(); sub_col1, sub_col2 = pagination_container.columns([2,1])
        with sub_col1: st.markdown(f"<div style='text-align: right; padding-top: 10px;'>æ€»è®¡: {len(df)} æ¡ï¼Œå…± {total_pages} é¡µ</div>", unsafe_allow_html=True)
        with sub_col2: st.number_input("é¡µç ", 1, total_pages, step=1, key=page_num_key, label_visibility="collapsed")
st.set_page_config(page_title="5Gåˆ†æµåˆ†æç³»ç»Ÿ (Leafletåœ°å›¾ç‰ˆ)", page_icon="ğŸ“¡", layout="wide"); st.title("ğŸ›°ï¸ 5Gåˆ†æµåˆ†æç³»ç»Ÿ (Leafletåœ°å›¾ç‰ˆ)")
st.sidebar.header("æ“ä½œé¢æ¿"); uploaded_4g_file = st.sidebar.file_uploader("1. ä¸Šä¼ 4Gå°åŒºå·¥å‚è¡¨ (Excel)", type=['xlsx', 'xls']); uploaded_5g_file = st.sidebar.file_uploader("2. ä¸Šä¼ 5Gå°åŒºå·¥å‚è¡¨ (Excel)", type=['xlsx', 'xls'])
st.sidebar.markdown("---"); st.sidebar.subheader("ç®—æ³•å‚æ•°"); d_colo = st.sidebar.number_input("å…±ç«™å€è·ç¦»é˜ˆå€¼ (ç±³)", 1, 500, 50); theta_colo = st.sidebar.number_input("å…±ç«™å€æ–¹ä½è§’åå·®é˜ˆå€¼ (åº¦)", 1, 180, 30); d_non_colo = st.sidebar.number_input("éå…±ç«™å€æœç´¢åŠå¾„ (ç±³)", 50, 2000, 300); n_non_colo = st.sidebar.number_input("éå…±ç«™å€5Gå°åŒºæ•°é‡é˜ˆå€¼ (ä¸ª)", 1, 10, 1)
st.sidebar.markdown("---")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'df_4g_preview' not in st.session_state: st.session_state.df_4g_preview = None; 
if 'df_5g_preview' not in st.session_state: st.session_state.df_5g_preview = None
if 'search_name' not in st.session_state: st.session_state.search_name = ""

# åŠ è½½å…¨éƒ¨æ•°æ®ç”¨äºé¢„è§ˆ
if uploaded_4g_file and st.session_state.df_4g_preview is None:
    try:
        st.session_state.df_4g_preview = pd.read_excel(uploaded_4g_file)
    except Exception as e:
        st.error(f"è¯»å–4Gæ–‡ä»¶é¢„è§ˆæ—¶å‡ºé”™ï¼š{e}")
        st.session_state.df_4g_preview = None

if uploaded_5g_file and st.session_state.df_5g_preview is None:
    try:
        st.session_state.df_5g_preview = pd.read_excel(uploaded_5g_file)
    except Exception as e:
        st.error(f"è¯»å–5Gæ–‡ä»¶é¢„è§ˆæ—¶å‡ºé”™ï¼š{e}")
        st.session_state.df_5g_preview = None

# æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
if st.session_state.df_4g_preview is not None:
    display_paginated_dataframe(st.session_state.df_4g_preview, "4Gæ•°æ®é¢„è§ˆ")
if st.session_state.df_5g_preview is not None:
    display_paginated_dataframe(st.session_state.df_5g_preview, "5Gæ•°æ®é¢„è§ˆ")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'analysis_done' not in st.session_state:
    st.session_state.analysis_done = False
if 'search_name' not in st.session_state:
    st.session_state.search_name = ""
if 'df_4g' not in st.session_state:
    st.session_state.df_4g = None
if 'df_5g' not in st.session_state:
    st.session_state.df_5g = None
if 'results_df' not in st.session_state:
    st.session_state.results_df = None

# åˆ†æå’Œåœ°å›¾æ˜¾ç¤ºé€»è¾‘
if st.sidebar.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary") or st.session_state.analysis_done:
    try:
        # å¦‚æœè¿˜æ²¡æœ‰å®Œæˆåˆ†æï¼Œåˆ™æ‰§è¡Œåˆ†æ
        if not st.session_state.analysis_done:
            # æ£€æŸ¥æ˜¯å¦ä¸Šä¼ äº†å¿…è¦çš„æ–‡ä»¶
            if not uploaded_4g_file or not uploaded_5g_file:
                st.error("è¯·å…ˆä¸Šä¼ 4Gå’Œ5Gå°åŒºå·¥å‚è¡¨æ–‡ä»¶ï¼")
                st.stop()
            
            with st.spinner("æ­£åœ¨é«˜æ•ˆåŠ è½½å’ŒéªŒè¯æ•°æ®..."):
                df_4g = load_and_validate_data(uploaded_4g_file, "4G")
                df_5g = load_and_validate_data(uploaded_5g_file, "5G")
            
            # éªŒè¯æ•°æ®é‡æ˜¯å¦åˆç†
            if len(df_4g) == 0:
                st.error("4Gæ•°æ®æ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®è¡Œï¼")
                st.stop()
            
            progress_bar = st.progress(0, text="åˆ†æå‡†å¤‡ä¸­...")
            
            def update_progress(current, total): 
                progress_bar.progress(current/total if total>0 else 0, text=f"æ­£åœ¨åˆ†æ: {current}/{total} æ¡è®°å½•...")
            
            results_df = analyze_5g_offload(df_4g, df_5g, d_colo, theta_colo, d_non_colo, n_non_colo, update_progress)
            progress_bar.progress(1.0, text="åˆ†æå®Œæˆï¼æ­£åœ¨å‡†å¤‡ç»“æœå±•ç¤º...")
            
            # ä¿å­˜æ•°æ®åˆ°ä¼šè¯çŠ¶æ€
            st.session_state.df_4g = df_4g
            st.session_state.df_5g = df_5g
            st.session_state.results_df = results_df
            st.session_state.analysis_done = True
        
        # ä»ä¼šè¯çŠ¶æ€ä¸­è·å–æ•°æ®
        df_4g = st.session_state.df_4g
        df_5g = st.session_state.df_5g
        results_df = st.session_state.results_df
        
        # æ˜¾ç¤ºåˆ†æç»“æœï¼Œæ— è®ºåœ°å›¾æ˜¯å¦å¯ç”¨
        st.markdown("---"); st.subheader("ğŸ“Š è¯¦ç»†åˆ†æç»“æœ")
        st.dataframe(results_df, use_container_width=True)
        
        # æ·»åŠ ç»“æœç»Ÿè®¡
        st.markdown("### åˆ†æç»“æœç»Ÿè®¡")
        total_4g = len(results_df)
        colo_offload = len(results_df[results_df['åˆ†æç»“æœ'].str.contains('å…±ç«™å€5Gåˆ†æµå°åŒº')])
        colo_tune = len(results_df[results_df['åˆ†æç»“æœ'].str.contains('å…±ç«™å€5Gå°„é¢‘è°ƒä¼˜å°åŒº')])
        non_colo_offload = len(results_df[results_df['åˆ†æç»“æœ'].str.contains('éå…±ç«™å€5Gåˆ†æµå°åŒº')])
        need_construction = len(results_df[results_df['åˆ†æç»“æœ'].str.contains('5Gè§„åˆ’å»ºè®¾')])
        
        col1, col2, col3, col4, col5 = st.columns(5)
        with col1: st.metric("æ€»4Gå°åŒºæ•°", total_4g)
        with col2: st.metric("å…±ç«™å€5Gåˆ†æµå°åŒº", colo_offload)
        with col3: st.metric("å…±ç«™å€å°„é¢‘è°ƒä¼˜å°åŒº", colo_tune)
        with col4: st.metric("éå…±ç«™å€5Gåˆ†æµå°åŒº", non_colo_offload)
        with col5: st.metric("éœ€è¦5Gè§„åˆ’å»ºè®¾å°åŒº", need_construction)
        
        # æ·»åŠ åœ°å›¾æœç´¢åŠŸèƒ½
        st.markdown("---")
        st.markdown("### ğŸ” åœ°å›¾æœç´¢")
        
        # ä½¿ç”¨è¡¨å•æ¥å¤„ç†æœç´¢ï¼Œç¡®ä¿åœ°å›¾ä¼šé‡æ–°ç”Ÿæˆ
        with st.form(key='search_form'):
            # æ·»åŠ æœç´¢è¾“å…¥æ¡†
            map_search_name = st.text_input(
                "è¯·è¾“å…¥å°åŒºåç§°åœ¨åœ°å›¾ä¸Šæœç´¢ï¼š", 
                value=st.session_state.search_name
            )
            
            # æ·»åŠ æœç´¢æŒ‰é’®
            search_submitted = st.form_submit_button("ğŸ” åœ¨åœ°å›¾ä¸Šæœç´¢")
            
            # å½“ç”¨æˆ·ç‚¹å‡»æœç´¢æŒ‰é’®æ—¶ï¼Œæ›´æ–°ä¼šè¯çŠ¶æ€
            if search_submitted:
                st.session_state.search_name = map_search_name
        
        # æ˜¾ç¤ºæœç´¢çŠ¶æ€
        if st.session_state.search_name:
            st.info(f"æ­£åœ¨æœç´¢åŒ…å« '{st.session_state.search_name}' çš„å°åŒº...")
        
        # ç”ŸæˆLeafletåœ°å›¾ï¼ˆç»Ÿä¸€çš„åœ°å›¾æ˜¾ç¤ºï¼‰
        st.markdown("---"); st.subheader("ğŸ—ºï¸ Leafletåœ°å›¾å¯è§†åŒ–ç»“æœ")
        
        # æ·»åŠ åœ°å›¾ç”Ÿæˆè¿›åº¦æç¤º
        map_progress = st.progress(0)
        map_progress.text("æ­£åœ¨å‡†å¤‡åœ°å›¾æ•°æ®...")
        
        try:
            # é™åˆ¶æ•°æ®é‡ä»¥æé«˜æ€§èƒ½
            map_progress.progress(20)
            map_progress.text("æ­£åœ¨å¤„ç†4Gæ•°æ®...")
            
            map_progress.progress(50)
            map_progress.text("æ­£åœ¨å¤„ç†æ•°æ®...")
            
            # è°ƒç”¨åœ°å›¾ç”Ÿæˆå‡½æ•°ï¼Œä¼ é€’æœç´¢åç§°
            map_obj = create_folium_map(df_4g, df_5g, results_df, None, st.session_state.search_name)
            
            map_progress.progress(100)
            map_progress.text("åœ°å›¾ç”Ÿæˆå®Œæˆï¼")
            
            # æ˜¾ç¤ºåœ°å›¾ç”Ÿæˆç»“æœ
            if isinstance(map_obj, str) and "åœ°å›¾ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™" in map_obj:
                st.error(map_obj)
            elif isinstance(map_obj, str) and "æ²¡æœ‰æœ‰æ•ˆ" in map_obj:
                st.warning(map_obj)
            else:
                # ä½¿ç”¨folium_staticæ˜¾ç¤ºåœ°å›¾å¯¹è±¡
                from streamlit_folium import folium_static
                folium_static(map_obj, width=1600, height=1200)
        except Exception as e:
            st.error(f"åœ°å›¾ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™ï¼š{e}")
            # æ˜¾ç¤ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            import traceback
            st.code(traceback.format_exc())
        finally:
            # æ¸…ç†è¿›åº¦æ¡
            map_progress.empty()
        
        output = BytesIO();
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            results_df.to_excel(writer, index=False, sheet_name='5Gåˆ†æµåˆ†æç»“æœ')
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯åˆ°Excel
            workbook = writer.book
            stats_sheet = workbook.create_sheet('åˆ†æç»Ÿè®¡')
            stats_data = [
                ['ç»Ÿè®¡é¡¹', 'æ•°é‡'],
                ['æ€»4Gå°åŒºæ•°', total_4g],
                ['å…±ç«™å€5Gåˆ†æµå°åŒº', colo_offload],
                ['å…±ç«™å€å°„é¢‘è°ƒä¼˜å°åŒº', colo_tune],
                ['éå…±ç«™å€5Gåˆ†æµå°åŒº', non_colo_offload],
                ['éœ€è¦5Gè§„åˆ’å»ºè®¾å°åŒº', need_construction]
            ]
            for row in stats_data:
                stats_sheet.append(row)
        
        st.download_button("ğŸ“¥ ä¸‹è½½åˆ†æç»“æœ", output.getvalue(), "5Gåˆ†æµåˆ†æç»“æœ.xlsx", "application/vnd.ms-excel")
            

        
    except ValueError as e:
        st.error(f"**æ•°æ®åŠ è½½æˆ–æ ¼å¼é”™è¯¯ï¼**\n\n**é”™è¯¯è¯¦æƒ…**: {e}")
        st.info("è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œç¡®ä¿åŒ…å«æ‰€æœ‰å¿…éœ€çš„åˆ—ï¼š['å°åŒºåç§°', 'ç»åº¦', 'çº¬åº¦', 'æ–¹ä½è§’']")
    except MemoryError:
        st.error("**å†…å­˜ä¸è¶³é”™è¯¯ï¼**\n\næ–‡ä»¶è¿‡å¤§ï¼Œæ— æ³•ä¸€æ¬¡æ€§å¤„ç†ã€‚è¯·å°è¯•ä½¿ç”¨è¾ƒå°çš„æ–‡ä»¶æˆ–è”ç³»ç®¡ç†å‘˜å¢åŠ æœåŠ¡å™¨èµ„æºã€‚")
    except Exception as e:
        st.error(f"**åˆ†æè¿‡ç¨‹ä¸­å‡ºç°æ„å¤–é”™è¯¯ï¼**\n\n**é”™è¯¯è¯¦æƒ…**: {type(e).__name__}: {e}")
        st.info("å¸¸è§åŸå› ï¼š\n1. æ•°æ®æ ¼å¼é—®é¢˜ï¼ˆå¦‚'ç»åº¦'æˆ–'çº¬åº¦'åˆ—åŒ…å«éæ•°å­—å†…å®¹ï¼‰\n2. æ–‡ä»¶æŸåæˆ–æ ¼å¼ä¸æ­£ç¡®\n3. ç™¾åº¦åœ°å›¾AKé…ç½®é—®é¢˜")
        
